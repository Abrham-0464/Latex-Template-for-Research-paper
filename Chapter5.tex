\chapter{CONCLUSIONS AND RECOMMENDATIONS}
\label{ch5}
\section{Introduction}
In this chapter, we summarize the overall findings of the study and present recommendations for future investigations. We discuss future research directions that could build upon both pre-existing and newly developed machine translation systems, with a particular focus on machine translation between the Xamtanga and English language pairs, as well as related tasks.
\section{Conclusion}
In this research, we have developed a bi-directional machine translation system for the English-Xamtanga language pair using deep learning models. A dataset of 18,860 sentences from diverse sources such as the Holy Bible, educational materials, mass media news, and historical documents was collected and preprocessed to ensure high-quality data for training. To address the translation task between Xamtanga and English, we explored three deep learning models: Bi-GRU, LSTM with Attention, and Transformer. These models were evaluated based on their performance to identify the most effective approach for translating between the two languages.\\\\
The results showed that the Transformer model outperformed both the Bi-GRU and LSTM with Attention models. It achieved BLEU scores of 18.4 for English to Xamtanga and 19.7 for Xamtanga to English, reflecting its ability to generate high quality translations. The Transformer also showed lower perplexity scores of 58.7 for English to Xamtanga and 48.2 for Xamtanga to English, indicating superior fluency. Moreover, it trained more efficiently, reducing both time and resource usage, which is critical for low-resource language pairs. The self-attention mechanism of the Transformer allowed it to handle long-range dependencies and the complex syntactic structures of Xamtanga, resulting in contextually accurate translations. However, challenges with very long sentences suggested the need for further optimization.\\\\
Our study also demonstrated that translating from Xamtanga to English yielded lower perplexity and higher BLEU scores compared to translating from English to Xamtanga across all models. This suggests that machine translation is more challenging when translating from morphologically simple to morphologically rich languages. Additionally, the translation from Xamtanga to English took less time, likely due to the shorter sentence lengths in Xamtanga, which required less encoding.\\\\
This research contributes to machine translation for low-resource languages, providing a valuable parallel dataset and demonstrating the effectiveness of the Transformer model. It offers insights into translating morphologically rich languages and paves the way for future advancements in neural machine translation for underrepresented language pairs.
\section{Recommendations for Future Research}
Based on the findings and limitations of this study, several directions for future research are recommended to enhance the English-Xamtanga machine translation system. First, we suggest expanding the training dataset to improve overall model performance and translation quality for the Xamtanga-English language pair. Given that this study focused on text-to-text translation, we also encourage exploring text-to-speech and speech-to-speech translation to further enhance system capabilities. Another key area for improvement is the performance decline when translating longer sentences. To address this, incorporating longer sentences into the training dataset and adjusting hyperparameters could optimize performance on such texts. Additionally, research into cross-lingual transfer learning is recommended to overcome data limitations by leveraging pre-trained multilingual models and related languages, which could lead to improved translation quality. Another promising avenue of research is the use of advanced preprocessing techniques, such as subword tokenization, to address language-specific challenges in Xamtanga, particularly in handling rare words. Moreover, collaboration with linguists and native speakers is crucial to improving dataset quality and ensuring that the system accurately reflects linguistic details. Finally, since data collection for low-resource languages like Xamtanga presents unique challenges, augmenting datasets and exploring methods to enhance the availability and quality of parallel datasets for English-Xamtanga translation will be vital. By addressing these recommendations, future research can significantly improve the English-Xamtanga machine translation system and contribute to the broader development of machine translation technologies for low-resource languages.
%CONCLUSIONS AND RECOMMENDATIONS
